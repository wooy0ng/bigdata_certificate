{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 작업형 제1유형"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../yemoonsaBigdata/datasets/Part3/301_housing.csv')\n",
    "\n",
    "# 데이터 중 결측치가 있는 경우 해당 데이터의 행을 모두 제거한다.\n",
    "df = df.dropna(axis=0)\n",
    "length = int(len(df) * 0.7)\n",
    "\n",
    "new_df = df.iloc[:length, :]\n",
    "q1 = new_df['housing_median_age'].quantile(0.25)\n",
    "print(q1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../yemoonsaBigdata/datasets/Part3/302_worlddata.csv')\n",
    "year_2000 = df[df['year'] == 2000]\n",
    "year_2000 = year_2000.T[1].drop(index=['year'])\n",
    "\n",
    "mean = df[df['year'] == 2000].T.mean().values[0]\n",
    "\n",
    "print(len(year_2000[year_2000 > mean]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../yemoonsaBigdata/datasets/Part3/303_titanic.csv')\n",
    "\n",
    "null = df.isnull().sum()\n",
    "print(null[null == null.max()].index.values[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "### 작업형 제2유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index    y_pred\n",
      "0     1569  0.249780\n",
      "1     1344  0.980985\n",
      "2     1429  0.110050\n",
      "3      896  0.421045\n",
      "4      101  0.981896\n",
      "..     ...       ...\n",
      "492   1376  0.116380\n",
      "493     87  0.004359\n",
      "494    287  0.165676\n",
      "495    337  0.425349\n",
      "496     92  0.111409\n",
      "\n",
      "[497 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X_train = pd.read_csv('../yemoonsaBigdata/datasets/Part3/304_x_train.csv')\n",
    "y_train = pd.read_csv('../yemoonsaBigdata/datasets/Part3/304_y_train.csv')\n",
    "X_test = pd.read_csv('../yemoonsaBigdata/datasets/Part3/304_x_test.csv')\n",
    "\n",
    "num_cols = ['Age', 'AnnualIncome', 'FamilyMembers', 'ChronicDiseases']\n",
    "cat_cols = ['Employment Type', 'GraduateOrNot', 'FrequentFlyer', 'EverTravelledAbroad']\n",
    "y_cols = ['TravelInsurance']\n",
    "\n",
    "# 범주형 데이터 전처리\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = pd.concat([X_train, X_test])\n",
    "for col in cat_cols:\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(X[col])\n",
    "    \n",
    "    X_train[col] = label_encoder.transform(X_train[col])\n",
    "    X_test[col] = label_encoder.transform(X_test[col])\n",
    "\n",
    "\n",
    "# 학습, 검증 데이터셋 \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train[num_cols+cat_cols], y_train[y_cols], test_size=0.3)\n",
    "\n",
    "# 수치형 데이터셋 전처리\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr[num_cols])\n",
    "\n",
    "X_tr[num_cols] = scaler.transform(X_tr[num_cols])\n",
    "X_val[num_cols] = scaler.transform(X_val[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "\n",
    "# 학습\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "\n",
    "model_xgb1 = XGBClassifier(n_estimators=50, max_depth=5)\n",
    "model_xgb1.fit(X_tr, y_tr.values.squeeze())\n",
    "y_pred = model_xgb1.predict(X_val)\n",
    "# print(accuracy_score(y_val, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# y_pred_proba = model_xgb1.predict_proba(X_val)\n",
    "# print(y_pred_proba[:, 1])\n",
    "# print(roc_auc_score(y_val, y_pred_proba[:, 1]))\n",
    "\n",
    "\n",
    "\n",
    "y_pred_proba = model_xgb1.predict_proba(X_test[num_cols+cat_cols])\n",
    "# print(y_pred_proba[:, 1])\n",
    "\n",
    "result = pd.DataFrame({\n",
    "    'index': X_test['ID'],\n",
    "    'y_pred': y_pred_proba[:, 1]\n",
    "})\n",
    "print(result)\n",
    "\n",
    "result.to_csv('../yemoonsaBigdata/res/3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
